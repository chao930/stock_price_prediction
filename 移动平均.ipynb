{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import talib\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ts.set_token('457a66c9299e50e9e0b2bf6c2f122bb24d560735f01b443158d1c85e')\n",
    "# 日线接口\n",
    "pro = ts.pro_api()\n",
    "# df = pro.daily(ts_code='000001.SH', start_date='20100701', end_date='20190923')\n",
    "df = ts.pro_bar(ts_code='000300.SH', asset='I', start_date='20100701', end_date='20191201')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "df.set_index('trade_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_index(ascending=True)\n",
    "plt.figure(figsize = (18,9))\n",
    "plt.plot(range(df.shape[0]),(df['low']), color='r')\n",
    "plt.plot(range(df.shape[0]),(df['high']), color = 'b')\n",
    "plt.xticks(range(0,df.shape[0],60),df.index[::60],rotation=60)\n",
    "plt.xlabel('trade_date',fontsize=18)\n",
    "plt.ylabel('Price',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prices = df.loc[:,'high'].values\n",
    "low_prices = df.loc[:,'low'].values\n",
    "mid_prices = (high_prices+low_prices)/2.0\n",
    "mid_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = int(mid_prices.shape[0]*0.95)\n",
    "train_data = mid_prices[:train_test_split]\n",
    "test_data = mid_prices[train_test_split:]\n",
    "train_data = train_data.reshape(-1,1)         #scaler.fit_transform\n",
    "test_data = test_data.reshape(-1,1)           #scaler.fit_transform\n",
    "\n",
    "print('%d training and %d total testing instances'%(len(train_data),    \n",
    "      len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplot with training data\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(train_data.shape[0]),train_data,color='r',label='Training split')\n",
    "plt.title('Train Data')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "#Subplot with test data\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(test_data.shape[0]),test_data,color='b',label='Test Split')\n",
    "plt.title('Test Data')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "#adjust layout and plot all\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window size to normalize data in chunks \n",
    "normalization_window = 250\n",
    "\n",
    "#Feature range for normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Loop over the training data in windows of 250 instances at a time\n",
    "for i in range(0,len(train_data),normalization_window):\n",
    "    \n",
    "    # Fit the scaler object on the data in the current window\n",
    "    scaler.fit(train_data[i:i+normalization_window,:])\n",
    "    \n",
    "    # Transform the data in the current window into values between the chosen feature range (0 and 1)\n",
    "    train_data[i:i+normalization_window,:] = scaler.transform(train_data[i:i+normalization_window,:])\n",
    "\n",
    "# normalize the the test data\n",
    "test_data=scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smoothing = 0.0     #Initialize smoothing value as zero\n",
    "gamma = 0.1         #Define decay\n",
    "for i in range(len(train_data)):  \n",
    "    Smoothing = gamma*train_data[i] + (1-gamma)*Smoothing   # Update smoothing Value  \n",
    "    train_data[i] = Smoothing # Replace datapoint with smoothened value"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 26            # Define window size\n",
    "N = train_data.size         # and length of observations\n",
    "\n",
    "std_avg_predictions = []    # Empty list to catch std\n",
    "mse_errors = []             # and mse\n",
    "\n",
    "for i in range(window_size,N):\n",
    "    # Append the standard mean per window\n",
    "    std_avg_predictions.append(np.mean(train_data[i-window_size:i]))                                                                                                         \n",
    " \n",
    "    # Compute mean squared error per batch \n",
    "    mse_errors.append((std_avg_predictions[-1]-train_data[i])**2) \n",
    "\n",
    "print('MSE error for standard averaging: %.5f' % (0.5*np.mean(mse_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (19,6))\n",
    "plt.plot(range(train_data.shape[0]),train_data,color='darkblue',label='Actual')\n",
    "plt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Predicted')\n",
    "plt.xticks(range(0,df.shape[0]-len(test_data),50),df.index[::50],rotation=45)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mid Price')\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_avg_predictions = []\n",
    "mse_errors = []\n",
    "\n",
    "EMA = 0.0\n",
    "ema_avg_predictions.append(EMA)\n",
    "\n",
    "gamma = 0.9\n",
    "window_size = 100\n",
    "N = len(train_data)\n",
    "\n",
    "for i in range(1,N):\n",
    "    EMA = EMA*gamma + (1.0-gamma)*train_data[i-1]\n",
    "    ema_avg_predictions.append(EMA)\n",
    "    mse_errors.append((ema_avg_predictions[-1]-train_data[i])**2)\n",
    "\n",
    "print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=7, foresight=3):   \n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-foresight): \n",
    "        obs = dataset[i:(i+look_back), 0] # Sequence of 7 stock prices as features forming an observation                                        \n",
    "       # Append sequence\n",
    "        X.append(obs)\n",
    "       # Append stock price value occurring 4 time-steps into future\n",
    "        Y.append(dataset[i + (look_back+foresight), 0]) \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_dataset(train_data)\n",
    "x_test, y_test = create_dataset(test_data)\n",
    "print(x_train.shape)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 1,  x_train.shape[1]))  #(990,1,7)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1,  x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from keras.layers import Dropout, Flatten\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def simple_gru():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128,  input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.1))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics = \n",
    "                  ['mse']) \n",
    "#   model.compile(loss='mae', optimizer='adam', metrics = \n",
    "#                   ['mean_absolute_error']) \n",
    "    return model\n",
    "\n",
    "def CNN():\n",
    "    model = Sequential()\n",
    "    model.add(input_shape=(7,))\n",
    "    model.add(Conv1D(100, 10, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "    model.add(Conv1D(100, 10, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(160, 10, activation='relu'))\n",
    "    model.add(Conv1D(160, 10, activation='relu'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def simple_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(1, 7)))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def lstm_stacked():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(1, 7), dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(16, dropout=0.1, recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(network):\n",
    "    plt.plot(network.history['loss'], label='loss')\n",
    "    plt.plot(network.history['val_loss'], label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, y_test=y_test):\n",
    "    \n",
    "    preds = model.predict(x_test)\n",
    "    plt.figure(figsize = (12,6))\n",
    "    plt.plot(scaler.inverse_transform(preds.reshape(-1,1)), \n",
    "             label='generated', color='orange')\n",
    "    plt.plot(scaler.inverse_transform(y_test.reshape(-1,1)),   \n",
    "             label='Actual')\n",
    "    plt.legend()\n",
    "    print(type(scaler.inverse_transform(preds.reshape(-1,1))))\n",
    "    print(scaler.inverse_transform(preds.reshape(-1,1)))\n",
    "#     p_price = pd.Series(scaler.inverse_transform(preds.reshape(-1,1).reshape(1,-1)))\n",
    "#     p_price.shape()\n",
    "# #     y_test.shape()\n",
    "#     pv = pd.DataFrame({'Predict': p_price, \n",
    "#                         'Actual': y_test\n",
    "#                        })\n",
    "#     print(pv)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(list, x_train, y_train, epochs=5):\n",
    "    for net in list:               \n",
    "        \n",
    "        network_name = str(net).split(' ')[1]\n",
    "#         filepath = network_name + \"_epoch-{epoch:02d}-loss-{loss:.4f}-.hdf5\"\n",
    "        print('Training:', network_name)\n",
    "#         checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "        callbacks_list = [TensorBoard(log_dir='./tmp/log')]\n",
    "        model = net()                  \n",
    "        \n",
    "        network = model.fit(x_train, y_train,\n",
    "                            validation_split=0.2,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=64,\n",
    "                            callbacks=callbacks_list)\n",
    "        model.summary()\n",
    "        score = model.evaluate(x_test, y_test, verbose=1)\n",
    "        print(\"Test score\", score[0])\n",
    "        print(\"Test accuracy\", score[1])\n",
    "        plot_predictions(model, y_test)\n",
    "        plot_losses(network)\n",
    "        \n",
    "    return network, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = [CNN]\n",
    "\n",
    "# all_networks = [feed_forward, simple_gru, simple_lstm, lstm_stacked]\n",
    "train_network(all_networks, x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}